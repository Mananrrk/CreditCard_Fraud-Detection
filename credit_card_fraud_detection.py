# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Oi0HKzSkCgAsM_LmPmWwRQQ2IDVbPjTV
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, precision_recall_curve, auc, confusion_matrix
from sklearn.pipeline import Pipeline

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

import xgboost as xgb
import shap
import joblib

RANDOM_STATE = 42

df = pd.read_csv("creditcard.csv")   # change path if needed
print("Shape:", df.shape)
print(df.head())
print("Class distribution:\n", df['Class'].value_counts(), "\nNormalized:\n", df['Class'].value_counts(normalize=True))

data = df.copy()
if 'Amount' in data.columns:
    data['Amount_scaled'] = (data['Amount'] - data['Amount'].mean()) / (data['Amount'].std() + 1e-9)
    # optional: drop original Amount
    data = data.drop(columns=['Amount'])
if 'Time' in data.columns:
    data['Hour'] = (data['Time'] // 3600) % 24
    # drop Time
    data = data.drop(columns=['Time'])

print("After FE shape:", data.shape)

X = data.drop(columns=['Class'])
y = data['Class']

# If you have a column 'date' or 'timestamp', use it for a time split. Here we'll do train/test by time if 'date' exists:
if 'date' in data.columns or 'timestamp' in data.columns:
    # Example: sort by timestamp and split (adjust column name to your dataset)
    ts_col = 'date' if 'date' in data.columns else 'timestamp'
    sorted_idx = data.sort_values(ts_col).index
    # 80% train, 20% test by time
    split_point = int(0.8 * len(sorted_idx))
    train_idx = sorted_idx[:split_point]
    test_idx = sorted_idx[split_point:]
    X_train, X_test = X.loc[train_idx], X.loc[test_idx]
    y_train, y_test = y.loc[train_idx], y.loc[test_idx]
else:
    # fallback: stratified random split (keeps class ratios)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y
    )

print("Train shape:", X_train.shape, "Test shape:", X_test.shape)
print("Train fraud ratio:", y_train.mean(), "Test fraud ratio:", y_test.mean())

smote = SMOTE(sampling_strategy=0.1, random_state=RANDOM_STATE)
# sampling_strategy=0.1 => minority becomes 10% of majority (tune this)

xgb_clf = xgb.XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.05,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=RANDOM_STATE,
    n_jobs=-1
)

pipe = ImbPipeline(steps=[
    ('smote', smote),
    ('scaler', StandardScaler()),   # scales numeric features
    ('clf', xgb_clf)
])

# Quick fit
pipe.fit(X_train, y_train)

y_proba = pipe.predict_proba(X_test)[:, 1]   # probability of fraud
# default threshold 0.5 (but we’ll tune)
y_pred_default = (y_proba >= 0.5).astype(int)

print("Classification report (threshold=0.5):")
print(classification_report(y_test, y_pred_default, digits=4))

cm = confusion_matrix(y_test, y_pred_default)
print("Confusion matrix:\n", cm)

prec, rec, thresh = precision_recall_curve(y_test, y_proba)
pr_auc = auc(rec, prec)
print(f"PR AUC: {pr_auc:.4f}")

plt.figure(figsize=(6,4))
plt.plot(rec, prec)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title(f'Precision-Recall curve (AUC={pr_auc:.4f})')
plt.grid(True)
plt.show()

target_recall = 0.90
idx = np.argmax(rec >= target_recall)
chosen_thresh = thresh[idx] if idx < len(thresh) else 0.5
print("Chosen threshold for recall>=%.2f -> %.4f" % (target_recall, chosen_thresh))

y_pred_tuned = (y_proba >= chosen_thresh).astype(int)
print(classification_report(y_test, y_pred_tuned, digits=4))

import shap
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# --- 0) safety: small background sample & sample for explanation
background = X_train.sample(n=min(200, len(X_train)), random_state=RANDOM_STATE)
X_sample = X_test.sample(n=min(200, len(X_test)), random_state=RANDOM_STATE)

# --- 1) create callable that returns prob of class 1
def model_predict_proba_positive(X):
    # SHAP may pass a numpy array — convert to DataFrame with correct columns
    if not isinstance(X, pd.DataFrame):
        X = pd.DataFrame(X, columns=background.columns)
    return pipe.predict_proba(X)[:, 1]

# --- 2) Try the modern/simple approach: shap.Explainer(callable, background)
try:
    explainer = shap.Explainer(model_predict_proba_positive, background)
    shap_vals = explainer(X_sample)   # new API object
    print("Used shap.Explainer successfully (new API).")
    # Plots (new API)
    print("Rendering global summary (beeswarm)...")
    shap.plots.beeswarm(shap_vals)       # global
    # Waterfall for first sample
    print("Rendering waterfall for first sample...")
    shap.plots.waterfall(shap_vals[0])
except Exception as e:
    print("shap.Explainer failed with:", repr(e))
    print("Falling back to KernelExplainer (slower).")

    # --- 3) Fallback: KernelExplainer (model-agnostic, but slow)
    # Use extremely small background for KernelExplainer to avoid long runtime
    ker_background = background.sample(n=min(50, len(background)), random_state=RANDOM_STATE)
    # KernelExplainer expects a function returning predictions for matrix input
    try:
        ke = shap.KernelExplainer(model_predict_proba_positive, ker_background)
        # compute shap values for a very small subset (e.g., 20 samples max)
        X_small = X_sample.sample(n=min(20, len(X_sample)), random_state=RANDOM_STATE)
        shap_vals_ker = ke.shap_values(X_small, nsamples=100)  # nsamples tradeoff speed/accuracy
        print("KernelExplainer succeeded. Plotting summary for small subset...")
        shap.summary_plot(shap_vals_ker, X_small)
    except Exception as e2:
        print("KernelExplainer also failed with:", repr(e2))
        print("As last resort, please tell me your shap.__version__ and xgboost.__version__ and I'll give version-specific code.")

param_grid = {
    'clf__n_estimators': [100, 200],
    'clf__max_depth': [4, 6],
    'clf__learning_rate': [0.05, 0.1],
}

grid = GridSearchCV(pipe, param_grid, scoring='average_precision', cv=3, n_jobs=-1, verbose=2)
grid.fit(X_train, y_train)
print("Best params:", grid.best_params_)
best_pipe = grid.best_estimator_

# Evaluate best
y_proba_grid = best_pipe.predict_proba(X_test)[:,1]
prec, rec, _ = precision_recall_curve(y_test, y_proba_grid)
print("Tuned PR AUC:", auc(rec, prec))

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Compute ROC curve and ROC area
fpr, tpr, thresholds = roc_curve(y_test, y_proba_grid)
roc_auc = auc(fpr, tpr)

# Plot
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

import pandas as pd
# sample some thresholds (avoid first and last)
df_pr = pd.DataFrame({'precision': prec[:-1], 'recall': rec[:-1], 'threshold': thresh})
# show thresholds with recall >= [0.9, 0.8, 0.7] etc.
for r in [0.95, 0.9, 0.85, 0.8, 0.7]:
    row = df_pr[df_pr['recall'] >= r].sort_values('recall', ascending=False).head(1)
    if not row.empty:
        print(f"Recall >= {r}: threshold={row['threshold'].values[0]:.6f}, precision={row['precision'].values[0]:.4f}, recall={row['recall'].values[0]:.4f}")
    else:
        print(f"Recall >= {r}: none found")
# show top 10 rows by precision (to see high-precision low-recall points)
print("\nTop 10 high-precision points:")
print(df_pr.sort_values('precision', ascending=False).head(10))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Get predicted classes
y_pred = (y_proba_grid >= 0.5).astype(int)  # threshold = 0.5

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Fraud', 'Fraud'])
disp.plot(cmap='Blues', values_format='d')
plt.title("Confusion Matrix - Credit Card Fraud Detection")
plt.show()

